library(shiny)
library(ggplot2)
library(dplyr)
library(magrittr)
library(lubridate)
library(tidyverse)
library(dygraphs)
library(xts)
library(tidytext)
library(wordcloud2)
library(kableExtra)
library(widyr)
library(ggraph)
library(igraph)
library(ggplot2)
library(plotly)
library(DT)
library(shinythemes)
library(shinycssloaders)
library(googleVis)
library(topicmodels)
library(tm)
library(tidytext)
library(shinydashboard)

setwd("C:/Users/yakin/OneDrive/document/R/R_PJ/shiny/QA_data/hiyari_data")

# -------------------------------------------------------------

# 元データを取り込んで加工しておく
hiyari_data <- read.csv("All_hiyari_2018_utf8.csv",header = T,fileEncoding = "UTF-8-BOM")

# rowdataの必要列
need_col <- c("レポート番号", "発生日", "発生時間", "ステータス", "TEAM名",
              "基地名.部署名", "標題", 
              "どうなった.結果..どんなヒヤリか", "どうすればよかったのか.問題点.不足点.", 
              "何故ヒヤリハットで済んだか", "対策実施状況.改善提案.要望.その他.",
              "年代", "現部署在籍年数", "ATA", 
              "e.ASSERTION関連事象", "エラー主要因.大項目.コード",
              "エラー主要因.中項目.コード", "リスクレベル評価.対策前.", "リスクレベル評価.対策後."
)
# 必要列抽出
hiyari_data %<>% select(need_col)

# 各columnの改行、タブを削除
for (i in 1:ncol(hiyari_data)){
  hiyari_data[, i] <- str_remove_all(hiyari_data[, i],"\n")
  hiyari_data[, i] <- str_remove_all(hiyari_data[, i],"\t")
  return
}

# 必要用行抽出
hiyari_data$発生日 <- as.Date(hiyari_data$発生日)
hiyari_data %<>% filter(発生日 >= as.Date("2018-04-01"))


# pulldownにする項目をfactorに
factor_list <- c("ステータス", "TEAM名", "基地名.部署名", "年代", "現部署在籍年数", "ATA", 
                 "e.ASSERTION関連事象", "エラー主要因.大項目.コード",
                 "エラー主要因.中項目.コード", "リスクレベル評価.対策前.", "リスクレベル評価.対策後.")

# factorに変換
hiyari_data[,factor_list] <- lapply(hiyari_data[,factor_list], as.factor) 

# テキスト合成列を持つリストも作っておく
text_mix <- mutate(hiyari_data,mix=paste(hiyari_data$標題,
                                         hiyari_data$何をしていた時..状況.背景.作業内容.,
                                         hiyari_data$どうして..理由.原因.,
                                         hiyari_data$どうすればよかったのか.問題点.不足点.,
                                         hiyari_data$どうなった.結果..どんなヒヤリか,
                                         sep=""))

# ストップワードの設定
stop_words <- c("た","に","の","を","が","て","っ","し","した","で","てい","と","じ",
                "作業","な","は","に","れ","い","って","さ","ため","から","か","だ","",
                "も","する","時","いる","f","r","b","為","あっ","ところ","しそう","そう",
                "h","後","ので","え","ず","け","ら","まで","ば","この","しか","ん","せ",
                "にし","り","わ","ま","あ","ぶつ","かけ","わ","こ","や","中","t","s","j",
                "a","e","q","i","み","なか","まっ","しよう","へ","なく","なる","おら",
                "その","よう","として","について","により","ある","んで","こと","き",
                "でき","あわや","ない","なり","ひやり","ヒヤリ","確認","において","まま",
                "しま","とき","えて","より","ことに","おり","1","2","間","違","く","づ",
                "あり","きだ","よ","すべ","では","による","す","め","お","だけ","べ","うく",
                "ク","など","という","itm2","itm","itm3","itm1","課")

# ---------------------------------------------------------------



#shinyServer(function(input, output) {
server <- function(input, output) {
  
  # dygraphのアウトプット----------------------------------------
  output$dygraph <- renderDygraph({
    dygraph_data <- hiyari_data %>% 
      filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
                TEAM名 %in% input$target1[1:6])
    # 時系列分析用データセット
    hiyari_count <- dygraph_data %>% group_by(発生日, TEAM名) %>% summarise(count = n()) 
    hiyari_count_sp <- hiyari_count %>%
      arrange(発生日) %>%
      spread(key = TEAM名, value = count, fill = 0) %>%
      as.data.frame() %>%
      read.zoo() %>% 
      as.xts()
    
    g <- dygraph(data=hiyari_count_sp)
    g <- dyRangeSelector(g,dateWindow = c(input$rangeday[1], input$rangeday[2]))
    g
    
  })
  
  # data_tbのアウトプット-----------------------------------------
  
  output$data_tb <- DT::renderDataTable({
    table_data <- hiyari_data %>% 
      filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
                TEAM名 %in% input$target1[1:6])
    datatable(table_data, filter='top', rownames = F, extensions = c('Buttons','FixedHeader'), 
    options=list(dom = 'Bfrtip', buttons = I('colvis'), pageLength = 4, fixedHeader = F, autoWidth = T))
  })
  
  # wordclooudのアウトプット--------------------------------------
  output$cloud <- renderWordcloud2({
    # wordcloudのためのデータセット
    text_data <- hiyari_data %>% 
      filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
                TEAM名 %in% input$target1[1:6])
    # 文章列結合
    text_mix <- mutate(text_data,mix=paste(text_data$標題,text_data$何をしていた時..状況.背景.作業内容.,
                                           text_data$どうして..理由.原因.,text_data$どうすればよかったのか.問題点.不足点.,
                                           sep=""))
    # 文書ごとに単語ばらし
    x <- unnest_tokens(text_mix,word,mix)
    # 改行と数字削除
    x$word <- str_remove_all(x$word,"\n")
    x$word <- str_remove_all(x$word,"\\d")
    #ストップワードを含む行を削除してカウント
    x %<>% filter(!(word %in% stop_words))
    x %<>% group_by(word) %>% summarise(count=n()) %>% top_n(1000) %>% arrange(desc(count)) %>% ungroup()
    colnames(x) <- c("Term","Freq")
    #wordcloudのアウトプット
    wordcloud2(x, size = 0.6, color="random-light", backgroundColor="black")
  })

  # 件数表のアウトプット----------------------------------------
  output$closstable <- DT::renderDataTable({
  closs_data <- hiyari_data %>% 
    filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
              TEAM名 %in% input$target1[1:6]) 
  closs_data <- closs_data %>% group_by(TEAM名, 基地名.部署名, 年代) %>% summarise(count=n()) %>% ungroup()
  
    
  datatable(closs_data, filter='top', rownames=F, extensions = c('Buttons'), 
            options=list(dom = 'Bfrtip', buttons = c('pdf', 'csv'),pageLength = 20,fixedHeader = TRUE, autoWidth=T))
  
} )
  
  # 件数グラフのアウトプット----------------------------------------
  output$countgraph <- renderGvis({
    count_data <- hiyari_data %>% 
      filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
                TEAM名 %in% input$target1[1:6]) 
    count_data <- count_data %>% group_by(TEAM名) %>% summarise(count=n()) %>%
                  ungroup()
    
    gvisColumnChart(count_data)
    
  } )
  
  # 件数グラフのアウトプット2----------------------------------------
  output$countgraph2 <- renderPlotly({
    count_data <- hiyari_data %>% 
      filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
                TEAM名 %in% input$target1[1:6]) 
    count_data <- count_data %>% group_by(TEAM名, 基地名.部署名) %>% summarise(count=n()) %>% ungroup()
    
    ggplot(count_data, aes(x = 基地名.部署名, y = count, fill = count)) + 
      geom_bar(stat = "identity") +
      facet_wrap(.~TEAM名, scales= "free", ncol = 3) +
      theme(axis.text.x=element_text(angle=90,hjust=1,size=7))
  } )
  
  # 共起ネットワークのアウトプット----------------------------------------
  output$net <- renderPlot({
  text_mix <- text_mix %>% 
      filter(発生日 >= input$rangeday[1], 発生日 <= input$rangeday[2],
                TEAM名 %in% input$target1[1:6])
  unnest_text_mix <- unnest_tokens(text_mix,word,mix)
  unnest_text_mix <- unnest_text_mix[,c(1,20)] %>% filter(!(word %in% stop_words))
  word_pairs <- unnest_text_mix %>% data.frame() %>% pairwise_count(word,レポート番号,sort=T,upper=F)
  
  #word_pairs <- mutate(word_pairs,n=(n/sum(n)))
  
  word_pairs_graph <- word_pairs %>%
    #filter(n>=0.00005) %>%
    top_n(50) %>% 
    graph_from_data_frame() %>%
    ggraph(layout="fr") +
    geom_edge_link(aes(edge_alpha=n,edge_width=n),edge_colour="cyan4") +
    geom_node_point(size=5) +
    geom_node_text(aes(label=name),repel=T,point.padding=unit(0.2,"lines")) +
    theme_void()
  
  word_pairs_graph
  })
  
}